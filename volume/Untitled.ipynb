{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import glob\n",
    "import re\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nocScraping(novelID, limit=0):\n",
    "   \n",
    "   #set UA\n",
    "   header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:62.0) Gecko/20100101 Firefox/62.0\"}\n",
    "   \n",
    "   #set cookie\n",
    "   cookie = {\"over18\": \"yes\"}\n",
    "   \n",
    "   #親URLをセット\n",
    "   chapterlistUrl = \"https://novel18.syosetu.com/\" + str(novelID) + \"/\"\n",
    "   responseCL  = requests.get(url=chapterlistUrl, headers=header, cookies=cookie)\n",
    "   chapterlistHtml = responseCL.content\n",
    "   soupCL = BeautifulSoup(chapterlistHtml, \"html.parser\")\n",
    "   sublist = soupCL.find_all(\"dl\", attrs={\"class\",\"novel_sublist2\"})\n",
    "   #print(len(sublist))\n",
    "   \n",
    "   \n",
    "   novelDirPass = \"data/\" + novelID\n",
    "   count = 1\n",
    "   \n",
    "   if(limit == 0):\n",
    "       countlimit = len(sublist) + 1\n",
    "   else:\n",
    "       countlimit = limit + 1\n",
    "   \n",
    "   while(count < countlimit):\n",
    "       #set url\n",
    "       url = \"https://novel18.syosetu.com/\" + str(novelID) + \"/\" + str(count) + \"/\"\n",
    "\n",
    "       #get html\n",
    "       response  = requests.get(url=url, headers=header, cookies=cookie)\n",
    "       html = response.content\n",
    "\n",
    "       #set BeautifulSoup\n",
    "       soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "       #scraping\n",
    "       mainText = soup.find(\"div\", attrs={\"id\":\"novel_honbun\"})\n",
    "       try:\n",
    "           mainTextLines = mainText.find_all(\"p\")\n",
    "       except AttributeError:\n",
    "           pass\n",
    "\n",
    "       allText = \"\"\n",
    "\n",
    "       for mainTextLine in mainTextLines:\n",
    "           text = str(mainTextLine)\n",
    "           text = re.sub(\"<p.*\\\">\",\"\",text)\n",
    "           text = re.sub(\"</p>\",\"\",text)\n",
    "           text = text.replace(\"<br/>\",\"\")\n",
    "           if(text != \"\"):\n",
    "               allText = allText + text + \"\\n\"\n",
    "\n",
    "       allText = re.sub(\"\\n\\n\",\"\\n\",allText)\n",
    "       allText = re.sub(\"　\",\"\",allText)\n",
    "       #print(allText)\n",
    "       \n",
    "       os.makedirs(novelDirPass, exist_ok=True)\n",
    "       newFilePass = novelDirPass + \"/\" + novelID + \"_\" + str(count) + \".txt\"\n",
    "       if not os.path.isfile(newFilePass):\n",
    "           with open(newFilePass, mode=\"w\", encoding=\"UTF-8\") as f:\n",
    "               f.write(allText)\n",
    "       \n",
    "       count = count +1\n",
    "       \n",
    "def getNcode(limit):\n",
    "   response = requests.get(\"https://api.syosetu.com/novel18api/api\",params={\"out\":\"json\",\"nocgenre\":1,\"sasie\":0,\"type\":\"re\",\"ispickup\":1,\"lim\":limit,\"of\":\"n\"})\n",
    "   #print(response.json()[1][\"ncode\"])\n",
    "   count = 1\n",
    "   ncodelist=[]\n",
    "   \n",
    "   while(count < limit+1):\n",
    "       ncodelist.append(response.json()[count][\"ncode\"])\n",
    "       count = count + 1\n",
    "   #print(ncodelist)\n",
    "   return ncodelist\n",
    "   \n",
    "\n",
    "def getNovelText(number,limit=0):\n",
    "   ncodelist = getNcode(number)\n",
    "   count = 1\n",
    "   while(count < number):\n",
    "       nocScraping(ncodelist[count],limit)\n",
    "       count = count + 1\n",
    "       print(\"count = \"+str(count)+\" (\"+str((count/number)*100)+\"%)\")\n",
    "       time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getNcode(10) # 関数テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getNovelText(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "\n",
    "from janome.tokenizer import Tokenizer\n",
    "t = Tokenizer()\n",
    "def extract_words(text):\n",
    "  tokens = t.tokenize(text)\n",
    "  return [token.base_form for token in tokens if token.part_of_speech.split(\",\")[0] in [\"名詞\", \"動詞\", \"形容詞\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in glob.glob(\"./data/*/*.txt\"):\n",
    "  with open(path , encoding=\"UTF-8\") as f:\n",
    "    try:\n",
    "      for s_line in f:\n",
    "        s_line = s_line.replace(\"<ruby><rb>\",\"\")\n",
    "        s_line = s_line.replace(\"</rb><rp>(</rp><rt>\",\"\")\n",
    "        s_line = s_line.replace(\"</rt><rp>(</rp></ruby>\",\"\")\n",
    "        word_list.append(extract_words(s_line))\n",
    "    except UnicodeDecodeError:\n",
    "      pass\n",
    "\n",
    "with open(\"./wordlist.txt\", mode=\"w\", encoding=\"UTF-8\") as f:\n",
    "  f.write(str(word_list))\n",
    "\n",
    "model = word2vec.Word2Vec(word_list , size=100, min_count=5, window=5, iter=100)\n",
    "model.save(\"dosukebe.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"オチンチン\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.run(['jupyter', 'nbconvert', '--to', 'python', 'Untitled.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
